# Обработка данных о погоде

Цель проекта - разработать ETL-пайплайн для обработки данных о прогнозах погоды. Приложение должно извлекать данные из предоставленного JSON, преобразовывать их в заданный формат и сохранять в виде CSV-файла.

Источник данных: API [Open-Meteo](https://open-meteo.com/)

### Задание
Необходимо:

- Реализовать чтение данных из JSON-файла, структура которого соответствует примеру ответа от API Open-Meteo.
- Выполнить необходимые преобразования исходных данных. Цель трансформации - привести данные к структуре, описанной в документе "Итоговая таблица".
- Сохранить обработанные данные в файл формата .csv.

В результате работы приложения должен быть создан CSV-файл с отформатированными данными прогноза погоды.

### Структура проекта
```
shift_weather/
|-- index.py                    # Основной скрипт с логикой загрузки и обработки данных
|-- test_basic.py               # Файл с тестами
|-- requirements.txt            # Зависимости проекта
|-- README.md                   # Описание проекта
|-- data/                       # Папка для данных (для файла с итоговой таблицы)
```

### Как запустить приложение
  1. Клонировать репозиторий
  2. Установить зависимости
     ``` pip install -r requirements.txt```
  3. Запустить приложение:
     ```python index.py```
  После запуска итоговый csv-файл в будет создан в date/final_table.csv.

Для запуска тестов:
```pytest test_basic.py```

#### Пояснение решений
В ходе реализации проекта были приняты следующие ключевые решения для обеспечения качества и корректности итоговых данных.

1. Изменение периода запрашиваемых данных.
Дата и время в исходном запросе к API были смещены на один месяц вперед. Это было сделано для того, чтобы получить полный набор данных, так как в прогнозах на первоначально указанные даты присутствовали пропуски (null) для некоторых погодных показателей.

2. Выбор формата времени в API
В запросе к API для параметра timeformat был выбран iso8601 вместо unixtime. Это решения было продиктовано проблемой с данными: при использовании unixtime, значения sunrise и sunset от API поступали некорректными. Чтобы гарантировать точность данных, пришлось отказаться от шага преобразования unixtime -> iso8601 и запрашивать данные сразу в целевом формате.

3. Обработка дубликатов
Итоговая таблица не содержит дубликатов. Каждая строка уникально идентифицируется столбцом datetime, который представляет собой временную метку для каждого часа прогноза. Таким образом, дополнительная проверка на дубликаты не требовалась.

  
